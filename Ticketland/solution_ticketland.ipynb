{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение контеста https://boosters.pro/champ_10\n",
    "\n",
    "### Амир Мирас Сабыргалиулы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import ffm\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold, KFold, GroupKFold, train_test_split\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "import scipy.sparse as sp\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные патчи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_only(df, *patterns):\n",
    "    columns = set()\n",
    "    for pattern in patterns:\n",
    "        columns |= set([x for x in df.columns if re.search(\"^{}\".format(pattern), x)])\n",
    "    return df[list(columns)]\n",
    "\n",
    "def df_omit(df, *patterns):\n",
    "    columns = set(df.columns)\n",
    "    for pattern in patterns:\n",
    "        columns &= set([x for x in df.columns if not bool(re.search(\"^{}\".format(pattern), x))])\n",
    "    return df[list(columns)]\n",
    "\n",
    "\n",
    "pd.DataFrame.only = df_only\n",
    "pd.DataFrame.omit = df_omit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработчики данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler_client_data(df):\n",
    "    h_df = pd.DataFrame()\n",
    "    h_df['fn:client_data:age'] = df['age']\n",
    "    h_df['fc:client_data:sex'] = df['sex'].map({'female': 0, 'male': 1})\n",
    "    h_df['dt:client_data:create'] = df['create_datetime']\n",
    "    h_df['id_user'] = df['id_user']\n",
    "    return h_df\n",
    "\n",
    "def handler_show_data(df, bag_of_words=True):\n",
    "    h_df = df.groupby('id_show').first().reset_index()\n",
    "    h_df['IdBuilding'] = df.groupby('id_show').apply(\n",
    "        lambda x: sum(x['IdBuilding'].apply(lambda x: [str(x)]), [])).values\n",
    "    h_df['fn:show_data:building_count'] = h_df['IdBuilding'].apply(len)\n",
    "    h_df = h_df.rename(\n",
    "        columns={\n",
    "            'organizer_id': 'id:show_data:organizer', \n",
    "            'age_category': 'fc:show_data:age_category', \n",
    "            'duration': 'fn:show_data:duration', \n",
    "            'parent_genre_id': 'list:show_data:parent_genre',\n",
    "            'child_genre_id': 'list:show_data:child_genre', \n",
    "            'IdBuilding': 'list:show_data:building', \n",
    "            'show_maxprice': 'fn:show_data:show_maxprice', \n",
    "            'show_minprice': 'fn:show_data:show_minprice', \n",
    "            'show_meanprice': 'fn:show_data:show_meanprice', \n",
    "            'show_stdprice': 'fn:show_data:show_stdprice' \n",
    "        }\n",
    "    )\n",
    "    find_numbers = lambda x: str(x) if x != x else re.findall(\"[0-9]+\", x)\n",
    "    h_df['list:show_data:child_genre'] = h_df['list:show_data:child_genre'].apply(find_numbers)\n",
    "    h_df['list:show_data:parent_genre'] = h_df['list:show_data:parent_genre'].apply(find_numbers)\n",
    "    return h_df\n",
    "\n",
    "def handler_impressions(df):\n",
    "    h_df = df.copy()\n",
    "    return h_df.rename(\n",
    "        columns={\n",
    "            'rank': 'fn:impressions:rank', \n",
    "            'event_datetime_m': 'dt:impressions:event'\n",
    "        }\n",
    "    ).sort_values('dt:impressions:event').reset_index(drop=True)\n",
    "\n",
    "def handler_no_impressions(df):\n",
    "    h_df = df.copy()\n",
    "    return h_df.rename(\n",
    "        columns={\n",
    "            'event_datetime_m': 'dt:no_impressions:event'\n",
    "        }\n",
    "    )\n",
    "\n",
    "def handler_show_images(df):\n",
    "    h_df = df.copy()\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            'image_id': 'id:show_images:image', \n",
    "        }\n",
    "    )\n",
    "\n",
    "def handler_show_rating(df):\n",
    "    h_df = df.copy()\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            'date_time': 'dt:show_rating', \n",
    "            'rating': 'fn:show_rating:rating',\n",
    "            'rating_count': 'fn:show_rating:rating_count',\n",
    "            'review_count': 'fn:show_rating:review_count'\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions = handler_impressions(pd.read_csv(\"impressions.сsv\", parse_dates=['event_datetime_m']))\n",
    "test_impressions = handler_impressions(pd.read_csv(\"test.csv\", parse_dates=['event_datetime_m']))\n",
    "click_impressions = handler_no_impressions(pd.read_csv(\"clicks_no_impressions.сsv\", parse_dates=['event_datetime_m']))\n",
    "show_data = handler_show_data(pd.read_csv(\"show_data.сsv\"))\n",
    "client_data = handler_client_data(pd.read_csv(\"client_data.сsv\", parse_dates=['create_datetime']))\n",
    "show_rating = handler_show_rating(pd.read_csv(\"show_rating.сsv\", parse_dates=['date_time']))\n",
    "show_images = handler_show_images(pd.read_csv(\"show_images.сsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([impressions, test_impressions]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt:impressions:event:hour'] = df['dt:impressions:event'].apply(\n",
    "    lambda x: datetime(x.year, x.month, x.day, x.hour))\n",
    "df['dt:impressions:event:day'] = df['dt:impressions:event'].apply(\n",
    "    lambda x: datetime(x.year, x.month, x.day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Маски для каждого месяца: будем обучаться на марте и предсказывать апрель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = (df['is_clicked'].notnull())\n",
    "apr = df['is_clicked'].isnull()\n",
    "yan = mask_train & (\n",
    "    df['dt:impressions:event'] < datetime(2017, 2, 1, 0, 0, 0)) & (\n",
    "    df['dt:impressions:event'] >= datetime(2017, 1, 1, 0, 0, 0))\n",
    "feb = mask_train & (\n",
    "    df['dt:impressions:event'] < datetime(2017, 3, 1, 0, 0, 0)) & (\n",
    "    df['dt:impressions:event'] >= datetime(2017, 2, 1, 0, 0, 0))\n",
    "mar = mask_train & (\n",
    "    df['dt:impressions:event'] >= datetime(2017, 3, 1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yan_no = (\n",
    "    click_impressions['dt:no_impressions:event'] < datetime(2017, 2, 1, 0, 0, 0)) & (\n",
    "    click_impressions['dt:no_impressions:event'] >= datetime(2017, 1, 1, 0, 0, 0))\n",
    "feb_no = (\n",
    "    click_impressions['dt:no_impressions:event'] < datetime(2017, 3, 1, 0, 0, 0)) & (\n",
    "    click_impressions['dt:no_impressions:event'] >= datetime(2017, 2, 1, 0, 0, 0))\n",
    "mar_no = (\n",
    "    click_impressions['dt:no_impressions:event'] < datetime(2017, 4, 1, 0, 0, 0)) & (\n",
    "    click_impressions['dt:no_impressions:event'] >= datetime(2017, 3, 1, 0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yan_sr = (\n",
    "    show_rating['dt:show_rating'] < datetime(2017, 2, 1)) & (\n",
    "    show_rating['dt:show_rating'] >= datetime(2017, 1, 1))\n",
    "feb_sr = (\n",
    "    show_rating['dt:show_rating'] < datetime(2017, 3, 1)) & (\n",
    "    show_rating['dt:show_rating'] >= datetime(2017, 2, 1))\n",
    "mar_sr = (\n",
    "    show_rating['dt:show_rating'] < datetime(2017, 4, 1)) & (\n",
    "    show_rating['dt:show_rating'] >= datetime(2017, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи по клиентам и мероприятиям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(show_data, on='id_show', how='left')\n",
    "df = df.merge(client_data, on='id_user', how='left')\n",
    "df = df.merge(show_images, on='id_show', how='left')\n",
    "df = df.merge(\n",
    "    df.groupby(['id_user', 'id_show']).size().reset_index().rename(\n",
    "        columns={0: 'fk:id_user_id_show'}), \n",
    "    on=['id_user', 'id_show'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fk:id_user'] = df['id_user'].map(df['id_user'].value_counts())\n",
    "df['fk:id_show'] = df['id_show'].map(df['id_show'].value_counts())\n",
    "\n",
    "df['fn:impressions:event:hour'] = df['dt:impressions:event'].dt.hour\n",
    "df['fn:impressions:event:weekday'] = df['dt:impressions:event'].dt.weekday\n",
    "df['fn:impressions:event:minute'] = df['dt:impressions:event'].dt.minute\n",
    "df['fc:show_images:have_image'] = df['id:show_images:image'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Счетчики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fm:event_id_user\n",
      "fm:event_id_user_id_show\n",
      "fm:event_id_user_rank\n",
      "fm:event_id_user_id_show_rank\n",
      "fm:event_id_show\n",
      "fm:event_id_show_rank\n",
      "fm:hour_id_user\n",
      "fm:hour_id_user_id_show\n",
      "fm:hour_id_user_rank\n",
      "fm:hour_id_user_id_show_rank\n",
      "fm:hour_id_show\n",
      "fm:hour_id_show_rank\n",
      "fm:day_id_user\n",
      "fm:day_id_user_id_show\n",
      "fm:day_id_user_rank\n",
      "fm:day_id_user_id_show_rank\n",
      "fm:day_id_show\n",
      "fm:day_id_show_rank\n"
     ]
    }
   ],
   "source": [
    "merge_columns = [\n",
    "    ['dt:impressions:event', 'id_user'],\n",
    "    ['dt:impressions:event', 'id_user', 'id_show'],\n",
    "    ['dt:impressions:event', 'id_user', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event', 'id_user', 'id_show', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event', 'id_show'],\n",
    "    ['dt:impressions:event', 'id_show', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:hour', 'id_user'],\n",
    "    ['dt:impressions:event:hour', 'id_user', 'id_show'],\n",
    "    ['dt:impressions:event:hour', 'id_user', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:hour', 'id_user', 'id_show', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:hour', 'id_show'],\n",
    "    ['dt:impressions:event:hour', 'id_show', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:day', 'id_user'],\n",
    "    ['dt:impressions:event:day', 'id_user', 'id_show'],\n",
    "    ['dt:impressions:event:day', 'id_user', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:day', 'id_user', 'id_show', 'fn:impressions:rank'],\n",
    "    ['dt:impressions:event:day', 'id_show'],\n",
    "    ['dt:impressions:event:day', 'id_show', 'fn:impressions:rank'],\n",
    "]\n",
    "\n",
    "for cols in merge_columns:\n",
    "    print('fm:{}'.format('_'.join([x.split(\":\")[-1] for x in cols])))\n",
    "    df = df.merge(\n",
    "        df.groupby(cols).size().reset_index().rename(\n",
    "            columns={0: 'fm:{}'.format('_'.join([x.split(\":\")[-1] for x in cols]))}), \n",
    "        on=cols,\n",
    "        how='left'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = df.loc[mar].copy()\n",
    "test = df.loc[apr].copy()\n",
    "val_train = df.loc[feb].copy()\n",
    "val_test = df.loc[mar].copy()\n",
    "\n",
    "y = df.loc[mar, 'is_clicked']\n",
    "y_train = df.loc[feb, 'is_clicked']\n",
    "y_test = df.loc[mar, 'is_clicked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи по кликабельности из clicks_no_impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_no_features(df, df_clicks, days=None, month=None):\n",
    "    max_date = df['dt:impressions:event'].min()\n",
    "    if days is not None:\n",
    "        min_date = max_date - relativedelta(days=days)\n",
    "        name = \"{}_days\".format(days)\n",
    "    elif month is not None:\n",
    "        min_date = max_date - relativedelta(month=month)\n",
    "        name = \"{}_month\".format(month)\n",
    "    else: \n",
    "        raise Exception\n",
    "    date = df_clicks['dt:no_impressions:event']\n",
    "    mask = (date >= min_date) & (date < max_date)\n",
    "    \n",
    "    return_df = df.merge(\n",
    "        df_clicks[mask].groupby(['id_user', 'id_show']).size().reset_index().rename(\n",
    "            columns={0: 'fi:id_user_id_show_{}'.format(name)}), \n",
    "        on=['id_user', 'id_show'],\n",
    "        how='left'\n",
    "    )\n",
    "    return_df['fi:id_user_{}'.format(name)] = return_df['id_user'].map(\n",
    "        df_clicks.loc[mask, 'id_user'].value_counts(normalize=True))\n",
    "    return_df['fi:id_show_{}'.format(name)] = return_df['id_show'].map(\n",
    "        df_clicks.loc[mask, 'id_show'].value_counts(normalize=True))\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train = click_no_features(val_train, click_impressions, month=1)\n",
    "val_train = click_no_features(val_train, click_impressions, days=3)\n",
    "val_train = click_no_features(val_train, click_impressions, days=7)\n",
    "val_train = click_no_features(val_train, click_impressions, days=14)\n",
    "val_train = click_no_features(val_train, click_impressions, days=21)\n",
    "val_train = click_no_features(val_train, click_impressions, days=45)\n",
    "\n",
    "val_test = click_no_features(val_test, click_impressions, month=1)\n",
    "val_test = click_no_features(val_test, click_impressions, days=3)\n",
    "val_test = click_no_features(val_test, click_impressions, days=7)\n",
    "val_test = click_no_features(val_test, click_impressions, days=14)\n",
    "val_test = click_no_features(val_test, click_impressions, days=21)\n",
    "val_test = click_no_features(val_test, click_impressions, days=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = click_no_features(train, click_impressions, month=1)\n",
    "train = click_no_features(train, click_impressions, days=3)\n",
    "train = click_no_features(train, click_impressions, days=7)\n",
    "train = click_no_features(train, click_impressions, days=14)\n",
    "train = click_no_features(train, click_impressions, days=21)\n",
    "train = click_no_features(train, click_impressions, days=45)\n",
    "\n",
    "test = click_no_features(test, click_impressions, month=1)\n",
    "test = click_no_features(test, click_impressions, days=3)\n",
    "test = click_no_features(test, click_impressions, days=7)\n",
    "test = click_no_features(test, click_impressions, days=14)\n",
    "test = click_no_features(test, click_impressions, days=21)\n",
    "test = click_no_features(test, click_impressions, days=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи по рейтингу мероприятия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_train = val_train.merge(\n",
    "    show_rating.loc[yan_sr, ['fn:show_rating:rating', 'fn:show_rating:rating_count', \n",
    "                         'fn:show_rating:review_count', 'id_show']\n",
    "               ].groupby('id_show').mean().reset_index().rename(\n",
    "        columns={\n",
    "            'fn:show_rating:rating': 'fs:show_rating:rating',\n",
    "            'fn:show_rating:rating_count': 'fs:show_rating:rating_count', \n",
    "            'fn:show_rating:review_count': 'fs:show_rating:review_count'\n",
    "        }), \n",
    "    on=['id_show'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "val_test = val_test.merge(\n",
    "    show_rating.loc[feb_sr, ['fn:show_rating:rating', 'fn:show_rating:rating_count', \n",
    "                         'fn:show_rating:review_count', 'id_show']\n",
    "               ].groupby('id_show').mean().reset_index().rename(\n",
    "        columns={\n",
    "            'fn:show_rating:rating': 'fs:show_rating:rating',\n",
    "            'fn:show_rating:rating_count': 'fs:show_rating:rating_count', \n",
    "            'fn:show_rating:review_count': 'fs:show_rating:review_count'\n",
    "        }), \n",
    "    on=['id_show'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(\n",
    "    show_rating.loc[feb_sr, ['fn:show_rating:rating', 'fn:show_rating:rating_count', \n",
    "                         'fn:show_rating:review_count', 'id_show']\n",
    "               ].groupby('id_show').mean().reset_index().rename(\n",
    "        columns={\n",
    "            'fn:show_rating:rating': 'fs:show_rating:rating',\n",
    "            'fn:show_rating:rating_count': 'fs:show_rating:rating_count', \n",
    "            'fn:show_rating:review_count': 'fs:show_rating:review_count'\n",
    "        }), \n",
    "    on=['id_show'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "test = test.merge(\n",
    "    show_rating.loc[mar_sr, ['fn:show_rating:rating', 'fn:show_rating:rating_count', \n",
    "                         'fn:show_rating:review_count', 'id_show']\n",
    "               ].groupby('id_show').mean().reset_index().rename(\n",
    "        columns={\n",
    "            'fn:show_rating:rating': 'fs:show_rating:rating',\n",
    "            'fn:show_rating:rating_count': 'fs:show_rating:rating_count', \n",
    "            'fn:show_rating:review_count': 'fs:show_rating:review_count'\n",
    "        }), \n",
    "    on=['id_show'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сглаженные средние по предыдущему месяцу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEB_MEAN = df.loc[feb, 'is_clicked'].mean()\n",
    "YAN_MEAN = df.loc[yan, 'is_clicked'].mean()\n",
    "MAR_MEAN = df.loc[mar, 'is_clicked'].mean()\n",
    "\n",
    "yan_user_mean = df.loc[yan].groupby('id_user')['is_clicked'].mean()\n",
    "feb_user_mean = df.loc[feb].groupby('id_user')['is_clicked'].mean()\n",
    "mar_user_mean = df.loc[mar].groupby('id_user')['is_clicked'].mean()\n",
    "\n",
    "yan_show_mean = df.loc[yan].groupby('id_show')['is_clicked'].mean()\n",
    "feb_show_mean = df.loc[feb].groupby('id_show')['is_clicked'].mean()\n",
    "mar_show_mean = df.loc[mar].groupby('id_show')['is_clicked'].mean()\n",
    "\n",
    "yan_user_size = df.loc[yan].groupby('id_user')['is_clicked'].size()\n",
    "feb_user_size = df.loc[feb].groupby('id_user')['is_clicked'].size()\n",
    "mar_user_size = df.loc[mar].groupby('id_user')['is_clicked'].size()\n",
    "\n",
    "yan_show_size = df.loc[yan].groupby('id_show')['is_clicked'].size()\n",
    "feb_show_size = df.loc[feb].groupby('id_show')['is_clicked'].size()\n",
    "mar_show_size = df.loc[mar].groupby('id_show')['is_clicked'].size()\n",
    "\n",
    "ALPHA = 2\n",
    "yan_user_target_ctr = (yan_user_mean * yan_user_size + ALPHA * YAN_MEAN) / (yan_user_size + ALPHA)\n",
    "feb_user_target_ctr = (feb_user_mean * feb_user_size + ALPHA * FEB_MEAN) / (feb_user_size + ALPHA)\n",
    "mar_user_target_ctr = (mar_user_mean * mar_user_size + ALPHA * MAR_MEAN) / (mar_user_size + ALPHA)\n",
    "\n",
    "yan_show_target_ctr = (yan_show_mean * yan_show_size + ALPHA * YAN_MEAN) / (yan_show_size + ALPHA)\n",
    "feb_show_target_ctr = (feb_show_mean * feb_show_size + ALPHA * FEB_MEAN) / (feb_show_size + ALPHA)\n",
    "mar_show_target_ctr = (mar_show_mean * mar_show_size + ALPHA * MAR_MEAN) / (mar_show_size + ALPHA)\n",
    "\n",
    "val_train['fo:id_user'] = val_train['id_user'].map(yan_user_target_ctr)\n",
    "val_test['fo:id_user'] = val_test['id_user'].map(feb_user_target_ctr)\n",
    "\n",
    "val_train['fo:id_show'] = val_train['id_show'].map(yan_show_target_ctr)\n",
    "val_test['fo:id_show'] = val_test['id_show'].map(feb_show_target_ctr)\n",
    "\n",
    "train['fo:id_user'] = train['id_user'].map(feb_user_target_ctr)\n",
    "test['fo:id_user'] = test['id_user'].map(mar_user_target_ctr)\n",
    "\n",
    "train['fo:id_show'] = train['id_show'].map(feb_show_target_ctr)\n",
    "test['fo:id_show'] = test['id_show'].map(mar_show_target_ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сглаженные средние по предыдущим месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEB_MEAN = df.loc[feb | yan, 'is_clicked'].mean()\n",
    "YAN_MEAN = df.loc[yan, 'is_clicked'].mean()\n",
    "MAR_MEAN = df.loc[mar | feb | yan, 'is_clicked'].mean()\n",
    "\n",
    "yan_user_mean = df.loc[yan].groupby('id_user')['is_clicked'].mean()\n",
    "feb_user_mean = df.loc[feb | yan].groupby('id_user')['is_clicked'].mean()\n",
    "mar_user_mean = df.loc[mar | feb | yan].groupby('id_user')['is_clicked'].mean()\n",
    "\n",
    "yan_show_mean = df.loc[yan].groupby('id_show')['is_clicked'].mean()\n",
    "feb_show_mean = df.loc[feb | yan].groupby('id_show')['is_clicked'].mean()\n",
    "mar_show_mean = df.loc[mar | feb | yan].groupby('id_show')['is_clicked'].mean()\n",
    "\n",
    "yan_user_size = df.loc[yan].groupby('id_user')['is_clicked'].size()\n",
    "feb_user_size = df.loc[feb | yan].groupby('id_user')['is_clicked'].size()\n",
    "mar_user_size = df.loc[mar | feb | yan].groupby('id_user')['is_clicked'].size()\n",
    "\n",
    "yan_show_size = df.loc[yan].groupby('id_show')['is_clicked'].size()\n",
    "feb_show_size = df.loc[feb | yan].groupby('id_show')['is_clicked'].size()\n",
    "mar_show_size = df.loc[mar | feb | yan].groupby('id_show')['is_clicked'].size()\n",
    "\n",
    "ALPHA = 3\n",
    "yan_user_target_ctr = (yan_user_mean * yan_user_size + ALPHA * YAN_MEAN) / (yan_user_size + ALPHA)\n",
    "feb_user_target_ctr = (feb_user_mean * feb_user_size + ALPHA * FEB_MEAN) / (feb_user_size + ALPHA)\n",
    "mar_user_target_ctr = (mar_user_mean * mar_user_size + ALPHA * MAR_MEAN) / (mar_user_size + ALPHA)\n",
    "\n",
    "yan_show_target_ctr = (yan_show_mean * yan_show_size + ALPHA * YAN_MEAN) / (yan_show_size + ALPHA)\n",
    "feb_show_target_ctr = (feb_show_mean * feb_show_size + ALPHA * FEB_MEAN) / (feb_show_size + ALPHA)\n",
    "mar_show_target_ctr = (mar_show_mean * mar_show_size + ALPHA * MAR_MEAN) / (mar_show_size + ALPHA)\n",
    "\n",
    "val_train['fr:id_user'] = val_train['id_user'].map(yan_user_target_ctr)\n",
    "val_test['fr:id_user'] = val_test['id_user'].map(feb_user_target_ctr)\n",
    "\n",
    "val_train['fr:id_show'] = val_train['id_show'].map(yan_show_target_ctr)\n",
    "val_test['fr:id_show'] = val_test['id_show'].map(feb_show_target_ctr)\n",
    "\n",
    "train['fr:id_user'] = train['id_user'].map(feb_user_target_ctr)\n",
    "test['fr:id_user'] = test['id_user'].map(mar_user_target_ctr)\n",
    "\n",
    "train['fr:id_show'] = train['id_show'].map(feb_show_target_ctr)\n",
    "test['fr:id_show'] = test['id_show'].map(mar_show_target_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = val_train.only('fm').columns.tolist()\n",
    "fc = val_train.only('fc').columns.tolist()\n",
    "fo = val_train.only('fo').columns.tolist()\n",
    "fn = val_train.only('fn').columns.tolist()\n",
    "fk = val_train.only('fk').columns.tolist()\n",
    "fs = val_train.only('fs').columns.tolist()\n",
    "fi = val_train.only('fi').columns.tolist()\n",
    "fr = val_train.only('fr').columns.tolist()\n",
    "\n",
    "columns = fm + fc + fo + fn + fk + fs + fi + fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метапризнаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_features(df_val, t_val, df_train, t_train, df_test, features):\n",
    "    models = [\n",
    "        LGBMClassifier(n_estimators=200, learning_rate=0.1, \n",
    "                     max_depth=4,\n",
    "                     random_state=1, n_jobs=-1),\n",
    "        LGBMRegressor(n_estimators=200, learning_rate=0.1, \n",
    "                     max_depth=5,\n",
    "                     random_state=1, n_jobs=-1),\n",
    "        XGBRegressor(n_estimators=200, learning_rate=0.1, \n",
    "                     max_depth=4,\n",
    "                     random_state=1, n_jobs=-1),\n",
    "        ensemble.ExtraTreesClassifier(n_jobs=-1, n_estimators=200, \n",
    "                                      max_depth=5, random_state=1),\n",
    "        ensemble.RandomForestClassifier(\n",
    "            n_jobs=-1, n_estimators=200, max_depth=5, random_state=1)\n",
    "    ]\n",
    "    imp = Imputer()\n",
    "    scaler = MinMaxScaler()\n",
    "    f_train = []\n",
    "    f_test = []\n",
    "    for model in tqdm_notebook(models):\n",
    "        model.fit(scaler.fit_transform(\n",
    "            imp.fit_transform(df_val[features].values)), t_val.values)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            f_tr = model.predict_proba(\n",
    "                scaler.transform(imp.transform(df_train[features].values)))[:, 1]\n",
    "        else:\n",
    "            f_tr = model.predict(\n",
    "                scaler.transform(imp.transform(df_train[features].values)))\n",
    "\n",
    "        model.fit(scaler.fit_transform(\n",
    "            imp.fit_transform(df_train[features].values)), t_train.values)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            f_te = model.predict_proba(\n",
    "                scaler.transform(imp.transform(df_test[features].values)))[:, 1]\n",
    "        else:\n",
    "            f_te = model.predict(\n",
    "                scaler.transform(imp.transform(df_test[features].values)))\n",
    "        f_train.append(f_tr.reshape(-1, 1))\n",
    "        f_test.append(f_te.reshape(-1, 1))\n",
    "    return pd.DataFrame(\n",
    "        np.concatenate(f_train, axis=1),\n",
    "        index=df_train.index\n",
    "    ), pd.DataFrame(\n",
    "        np.concatenate(f_test, axis=1),\n",
    "        index=df_test.index\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbeb131c84e4856af9665a2b2e8e057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d15acd135c14942959e67d2b614ac89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa75e7394a554e9ea1e15f7475363250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mcnk = fm + fc + fn + fk\n",
    "mkois = fm + fk + fo + fi + fs\n",
    "mnkoi = fm + fn + fk + fo + fi\n",
    "\n",
    "mcnk_train, mcnk_test = meta_features(val_train, y_train, train, y, test, mcnk)\n",
    "mkois_train, mkois_test = meta_features(val_train, y_train, train, y, test, mkois)\n",
    "mnkoi_train, mnkoi_test = meta_features(val_train, y_train, train, y, test, mnkoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train = [mcnk_train, mkois_train, mnkoi_train]\n",
    "\n",
    "meta_test = [mcnk_test, mkois_test, mnkoi_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_train = []\n",
    "f_test = []\n",
    "for i, meta in enumerate(meta_train):\n",
    "    meta.columns = [\n",
    "        \"lgbclf_{}\".format(i),\n",
    "        \"lgbreg_{}\".format(i),\n",
    "        \"xgbreg_{}\".format(i),\n",
    "        \"etclf_{}\".format(i),\n",
    "        \"rfclf_{}\".format(i),\n",
    "    ]\n",
    "    f_train.append(meta)\n",
    "\n",
    "for i, meta in enumerate(meta_test):\n",
    "    meta.columns = [\n",
    "        \"lgbclf_{}\".format(i),\n",
    "        \"lgbreg_{}\".format(i),\n",
    "        \"xgbreg_{}\".format(i),\n",
    "        \"etclf_{}\".format(i),\n",
    "        \"rfclf_{}\".format(i),\n",
    "    ]\n",
    "    f_test.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_train = pd.concat(f_train, axis=1)\n",
    "stack_test = pd.concat(f_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbclf_0 0.114758013355\n",
      "lgbreg_0 0.397655539248\n",
      "xgbreg_0 0.360116542298\n",
      "etclf_0 0.249134746924\n",
      "rfclf_0 0.093029819474\n",
      "lgbclf_1 0.114006274527\n",
      "lgbreg_1 0.389707535492\n",
      "xgbreg_1 0.118376452903\n",
      "etclf_1 0.261404240198\n",
      "rfclf_1 0.0926040159345\n",
      "lgbclf_2 0.106920849378\n",
      "lgbreg_2 0.39599138448\n",
      "xgbreg_2 0.304324002502\n",
      "etclf_2 0.267616010386\n",
      "rfclf_2 0.0915280882243\n"
     ]
    }
   ],
   "source": [
    "filt = []\n",
    "for col in stack_train.columns:\n",
    "    if log_loss(\n",
    "            y, \n",
    "            np.concatenate(\n",
    "                [1 - stack_train[col].values.reshape(-1, 1), stack_train[col].values.reshape(-1, 1)], axis=1\n",
    "            )\n",
    "        ) <= 0.3:\n",
    "        filt.append(col)\n",
    "\n",
    "    print(col, \n",
    "        log_loss(\n",
    "            y, \n",
    "            np.concatenate(\n",
    "                [1 - stack_train[col].values.reshape(-1, 1), stack_train[col].values.reshape(-1, 1)], axis=1\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain = stack_train[filt]\n",
    "stest = stack_test[filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучаем 5 lgb-ов и усредняем ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135920757928\n",
      "0.136250732593\n",
      "0.136172055813\n",
      "0.136474041405\n",
      "0.136439349003\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "for i in [0, 1, 2, 3, 4]:\n",
    "    lgb = LGBMClassifier(n_estimators=420, learning_rate=0.01, \n",
    "                         max_depth=6, subsample=1.0 - i / 100,\n",
    "                         random_state=i * 777, n_jobs=-1)\n",
    "    lgb.fit(pd.concat([train[columns], strain], axis=1).values, y.values)\n",
    "    preds = lgb.predict_proba(pd.concat([test[columns], stest], axis=1).values)\n",
    "    print(preds[:, 1].mean())\n",
    "    p.append(preds[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135920757928\n",
      "0.136250732593\n",
      "0.136172055813\n",
      "0.136474041405\n",
      "0.136439349003\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for ans in p:\n",
    "    preds.append(ans)\n",
    "    print(ans.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(np.mean(preds, axis=0), index=test['id'].astype(int)).rename_axis(\n",
    "    {0: 'answer'}, axis=1)\n",
    "sub.to_csv('stackv11.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
